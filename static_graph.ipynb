{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P_Ce7SeCdMy",
        "outputId": "348884e3-eb08-497e-a5d8-ce0af650b4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load our graph data from drive, if you run it locally, ignore this\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8kZiJr6HCXH",
        "outputId": "831ede04-11ac-443c-ba7f-eb03b34bcef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import networkx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "AUQ2QzsIGNXk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/df_agg (1).pkl','rb')\n",
        "df_agg = pickle.load(file)\n",
        "df_agg.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gjXOKYdCp8F",
        "outputId": "456dbd6d-6594-4ceb-91f3-107158a9b31b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 17544 entries, 2012-01-01 00:00:00 to 2013-12-31 23:00:00\n",
            "Columns: 5558 entries, 2 to 5564\n",
            "dtypes: float64(5558)\n",
            "memory usage: 744.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/windows_agg_ids (2).pkl','rb')\n",
        "windows = pickle.load(file)\n",
        "windows.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOmcP3OJGfZU",
        "outputId": "5796f03f-94f1-4b5c-cec4-2b8bb1da8317"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5558 entries, 0 to 5557\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype          \n",
            "---  ------       --------------  -----          \n",
            " 0   LCLid        5558 non-null   int64          \n",
            " 1   Enabled At   5558 non-null   datetime64[ns] \n",
            " 2   Disabled At  5558 non-null   datetime64[ns] \n",
            " 3   Duration     5558 non-null   timedelta64[ns]\n",
            "dtypes: datetime64[ns](2), int64(1), timedelta64[ns](1)\n",
            "memory usage: 217.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter nodes that are active from 2012-11-01(7320) to 2013-11-01(16079)"
      ],
      "metadata": {
        "id": "qAYTN7JxG30u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "bJ1Vq9Vpnwni"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestampidx = 7320\n",
        "active_nodes = df_agg.columns[df_agg.loc[df_agg.index[timestampidx], :].notna()].to_numpy()\n",
        "for timestampidx in tqdm(range(7321, 16080)):\n",
        "  act = df_agg.columns[df_agg.loc[df_agg.index[timestampidx], :].notna()].to_numpy()\n",
        "  active_nodes = np.intersect1d(act, active_nodes)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df6lbyqjp6k",
        "outputId": "b1466009-e063-4e11-de44-1c77dd26fcba"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8759/8759 [00:49<00:00, 177.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(active_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCBnyiw-obe6",
        "outputId": "6d319a92-d09f-499f-9d85-9fcecd095d35"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3708"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence we only have 3708 nodes that are active from all timestamp in this period. If we would like more nodes, we could make interpolations."
      ],
      "metadata": {
        "id": "vuHK8TbfofxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "4G2iR5r_pKTE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwdFKoDcpP4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MGTNN\n",
        "\n",
        "paper:https://arxiv.org/abs/2005.11650\n",
        "\n",
        "code: https://github.com/nnzhan/MTGNN/tree/master\n",
        "\n",
        "A interesting framework which uses time-series data to make predictions.\n",
        "The most impotant part is that this framework learn both the graph structure and GNN. That is, in their data they don't have a predefined graph structure at  first (like us), so they have a graph learning layer which learns the adjacency matrix from the time-series data. The learned adjacency matrix then is input to the graph convolution layer and temporal layer."
      ],
      "metadata": {
        "id": "GYFqRZd4pQTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph learning layer\n",
        "\n",
        "In their work they choose to learn directed graph.\n",
        "Code below shows the example an un-directed graph learning layer."
      ],
      "metadata": {
        "id": "XzjP7krNrasm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class graph_undirected(nn.Module):\n",
        "    def __init__(self, nnodes, k, dim, device, alpha=3, static_feat=None):\n",
        "        super(graph_undirected, self).__init__()\n",
        "        self.nnodes = nnodes\n",
        "        if static_feat is not None:\n",
        "            xd = static_feat.shape[1]\n",
        "            self.lin1 = nn.Linear(xd, dim)\n",
        "        else:\n",
        "            self.emb1 = nn.Embedding(nnodes, dim)\n",
        "            self.lin1 = nn.Linear(dim,dim)\n",
        "\n",
        "        self.device = device\n",
        "        self.k = k\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.static_feat = static_feat\n",
        "\n",
        "    def forward(self, idx):\n",
        "        if self.static_feat is None:\n",
        "            nodevec1 = self.emb1(idx)\n",
        "            nodevec2 = self.emb1(idx)\n",
        "        else:\n",
        "            nodevec1 = self.static_feat[idx,:]\n",
        "            nodevec2 = nodevec1\n",
        "\n",
        "        nodevec1 = torch.tanh(self.alpha*self.lin1(nodevec1))\n",
        "        nodevec2 = torch.tanh(self.alpha*self.lin1(nodevec2))\n",
        "\n",
        "        a = torch.mm(nodevec1, nodevec2.transpose(1,0))\n",
        "        adj = F.relu(torch.tanh(self.alpha*a))\n",
        "        mask = torch.zeros(idx.size(0), idx.size(0)).to(self.device)\n",
        "        mask.fill_(float('0'))\n",
        "        s1,t1 = adj.topk(self.k,1)\n",
        "        mask.scatter_(1,t1,s1.fill_(1))\n",
        "        adj = adj*mask\n",
        "        return adj\n"
      ],
      "metadata": {
        "id": "0VTnhDMcraUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thought**: if we do not learn adj matrix in the framework, is it ok if we build the adj matrix from the similarity between time series data (maybe computation expensive)"
      ],
      "metadata": {
        "id": "U4ZrY3I0sORe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN and TCN\n",
        "For GCN layer they use mix hop propogation.\n",
        "For TCN layer they use dilated inception layer.\n",
        "Those two are fancy but may not easy to use. We could choose simplier one."
      ],
      "metadata": {
        "id": "l-I5vPNPs4dQ"
      }
    }
  ]
}